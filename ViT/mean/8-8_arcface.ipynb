{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93d032c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_metric_learning import losses\n",
    "from einops import rearrange, repeat\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5037ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_embed(embeds, file):\n",
    "    emb = []\n",
    "    for f in file:\n",
    "        emb.append(embeds[f][0])\n",
    "    return torch.stack(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df96ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NUM_PATCHES = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05ec6e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77aa75d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdienceDataset(Dataset):\n",
    "    def __init__(self, annot_file, img_dir):\n",
    "        self.img_lbls = pd.read_csv(annot_file, header=None)\n",
    "        self.img_dir = img_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_lbls)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_file = self.img_lbls.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_file)\n",
    "        image = mx.image.imread(img_path)\n",
    "        if image.shape[1] != 112:\n",
    "            image = mx.image.resize_short(image, 112)\n",
    "        image = mx.nd.transpose(image, axes=(2,0,1))\n",
    "        image = torch.tensor(image.asnumpy()).type(torch.FloatTensor)\n",
    "        label = self.img_lbls.iloc[idx, 1]\n",
    "\n",
    "        return image, label, img_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376748ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = AdienceDataset(\"../train.csv\", \"../cropped_Adience/\")\n",
    "val_data = AdienceDataset(\"../val.csv\", \"../cropped_Adience/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eebac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosFace(nn.Module):\n",
    "    r\"\"\"Implement of CosFace (https://arxiv.org/pdf/1801.09414.pdf):\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        device_id: the ID of GPU where the model will be trained by model parallel.\n",
    "                       if device_id=None, it will be trained on CPU without model parallel.\n",
    "        s: norm of input feature\n",
    "        m: margin\n",
    "        cos(theta)-m\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, device_id, s=64.0, m=0.35):\n",
    "        super(CosFace, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.device_id = device_id\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        print(\"self.device_id\", self.device_id)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "\n",
    "        if self.device_id == None:\n",
    "            cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        else:\n",
    "            x = input\n",
    "            sub_weights = torch.chunk(self.weight, len(self.device_id), dim=0)\n",
    "            temp_x = x.cuda(self.device_id[0])\n",
    "            weight = sub_weights[0].cuda(self.device_id[0])\n",
    "            cosine = F.linear(F.normalize(temp_x), F.normalize(weight))\n",
    "            for i in range(1, len(self.device_id)):\n",
    "                temp_x = x.cuda(self.device_id[i])\n",
    "                weight = sub_weights[i].cuda(self.device_id[i])\n",
    "                cosine = torch.cat((cosine, F.linear(F.normalize(temp_x), F.normalize(weight)).cuda(self.device_id[0])),\n",
    "                                   dim=1)\n",
    "        phi = cosine - self.m\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        one_hot = torch.zeros(cosine.size())\n",
    "        if self.device_id != None:\n",
    "            one_hot = one_hot.cuda(self.device_id[0])\n",
    "        # one_hot = one_hot.cuda() if cosine.is_cuda else one_hot\n",
    "\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + (\n",
    "                    (1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n",
    "        output *= self.s\n",
    "\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "               + 'in_features = ' + str(self.in_features) \\\n",
    "               + ', out_features = ' + str(self.out_features) \\\n",
    "               + ', s = ' + str(self.s) \\\n",
    "               + ', m = ' + str(self.m) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5c9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dd30549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bcc61c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a26412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), qkv)\n",
    "        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
    "        mask_value = -torch.finfo(dots.dtype).max\n",
    "        #embed()\n",
    "        if mask is not None:\n",
    "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
    "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
    "            mask = mask[:, None, :] * mask[:, :, None]\n",
    "            dots.masked_fill_(~mask, mask_value)\n",
    "            del mask\n",
    "\n",
    "        attn = dots.softmax(dim=-1)\n",
    "\n",
    "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        out =  self.to_out(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9030cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Residual(PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout))),\n",
    "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout)))\n",
    "            ]))\n",
    "    def forward(self, x, mask = None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, mask = mask)\n",
    "            #embed()\n",
    "            x = ff(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e39eb7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_face(nn.Module):\n",
    "    def __init__(self, *, loss_type, GPU_ID, num_class, image_size, patch_size, dim, depth, heads, mlp_dim, pool = 'mean', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = channels * patch_size ** 2\n",
    "        assert num_patches > MIN_NUM_PATCHES, f'your number of patches ({num_patches}) is way too small for attention to be effective (at least 16). Try decreasing your patch size'\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "        self.loss_type = loss_type\n",
    "        self.GPU_ID = GPU_ID\n",
    "        if self.loss_type == 'None':\n",
    "            print(\"no loss for vit_face\")\n",
    "        else:\n",
    "            if self.loss_type == 'CosFace':\n",
    "                self.loss = CosFace(in_features=dim, out_features=num_class, device_id=self.GPU_ID)\n",
    "\n",
    "    def forward(self, img, label=None, mask=None):\n",
    "        p = self.patch_size\n",
    "        \n",
    "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p)\n",
    "        x = self.patch_to_embedding(x)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x, mask)\n",
    "\n",
    "        y = x[:, 0]\n",
    "        z = x[:, 1:].mean(dim = 1)\n",
    "\n",
    "        y = self.to_latent(y)\n",
    "        emb_y = self.mlp_head(y)\n",
    "        z = self.to_latent(z)\n",
    "        emb_z = self.mlp_head(z)\n",
    "        emb = torch.cat((emb_y, emb_z), dim=1)\n",
    "        if label is not None:\n",
    "            x = self.loss(emb, label)\n",
    "            return x, emb\n",
    "        else:\n",
    "            return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7739e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_plus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ViT_plus, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=1024, out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x_cosface = x\n",
    "        x_classification = self.fc2(x)\n",
    "        \n",
    "        return x_cosface, x_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37eaea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.device_id [device(type='cuda', index=1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT_face(\n",
    "            image_size=112,\n",
    "            patch_size=8,\n",
    "            loss_type='CosFace',\n",
    "            GPU_ID= [device],\n",
    "            num_class=93431,\n",
    "            dim=512,\n",
    "            depth=20,\n",
    "            heads=8,\n",
    "            mlp_dim=2048,\n",
    "            dropout=0.1,\n",
    "            emb_dropout=0.1\n",
    "        ).to(device)\n",
    "model.load_state_dict(\n",
    "    torch.load(\"../Backbone_VIT_Epoch_2_Batch_20000_Time_2021-01-12-16-48_checkpoint.pth\", map_location=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2b665ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d81a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = {}\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, label, file in train_data:\n",
    "        img = img.to(device)\n",
    "        embeds[file] = model(torch.unsqueeze(img, 0))\n",
    "\n",
    "    for img, label, file in val_data:\n",
    "        img = img.to(device)\n",
    "        embeds[file] = model(torch.unsqueeze(img, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1aefc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accu = 0.9446246027946472\n",
    "def objective(trial):\n",
    "    model_xtr = ViT_plus().to(device)\n",
    "    \n",
    "    loss_lr = trial.suggest_float(\"loss_learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    arc_margin = losses.ArcFaceLoss(2, 1024).to(device)\n",
    "    loss_optimizer = opt.AdamW(arc_margin.parameters(), lr=loss_lr)\n",
    "    \n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    wd = trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True)\n",
    "    eps = trial.suggest_float(\"epsilon\", 1e-9, 1e-7, log=True)\n",
    "    optimizer = opt.AdamW(model_xtr.parameters(), lr=lr, eps=eps, weight_decay=wd)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    batch_size = trial.suggest_int('batch_size', 50, 300)\n",
    "    num_epochs = trial.suggest_int('epochs', 10, 100)\n",
    "    \n",
    "    print(\"Learning rate for Loss: \"+ str(loss_lr))\n",
    "    print(\"Learning rate: \"+ str(lr))\n",
    "    print(\"Weight decay: \"+ str(wd))\n",
    "    print(\"Epsilon: \"+ str(eps))\n",
    "    print(\"Batch size: \"+ str(batch_size))\n",
    "    print(\"Number of epochs: \"+ str(num_epochs))\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "        \n",
    "        # training loop\n",
    "        running_loss = []\n",
    "        running_accu = []\n",
    "        \n",
    "        model_xtr.train()\n",
    "        for img, label, file in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            x = file_to_embed(embeds, file)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            embed, output = model_xtr(x)\n",
    "            \n",
    "            pred = torch.argmax(output, 1)\n",
    "            accuracy = torch.eq(pred, label).sum() / len(img)\n",
    "\n",
    "            class_loss = criterion(output, label)\n",
    "            arc_loss = arc_margin(embed, label)\n",
    "            loss = class_loss + arc_loss\n",
    "            loss.backward()\n",
    "            loss_optimizer.step()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_accu.append(accuracy.cpu().detach().numpy())\n",
    "            running_loss.append(loss.cpu().detach().numpy())\n",
    "        print(\"Epoch: {}/{} - Loss: {:.4f} - Accuracy: {:.4f}\".format(epoch+1, num_epochs, np.mean(running_loss), np.mean(running_accu)))\n",
    "        \n",
    "        # validation loop\n",
    "        val_loss = []\n",
    "        val_accu = []\n",
    "\n",
    "        model_xtr.eval()\n",
    "        with torch.no_grad():\n",
    "            for img, label, file in tqdm(val_loader):\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                \n",
    "                x = file_to_embed(embeds, file)\n",
    "                \n",
    "                embed, output = model_xtr(x)\n",
    "                \n",
    "                pred = torch.argmax(output, 1)\n",
    "                accuracy = torch.eq(pred, label).sum() / len(img)\n",
    "                \n",
    "                class_loss = criterion(output, label)\n",
    "                arc_loss = arc_margin(embed, label)\n",
    "                loss = class_loss + arc_loss\n",
    "                \n",
    "                val_accu.append(accuracy.cpu().detach().numpy())\n",
    "                val_loss.append(loss.cpu().detach().numpy())\n",
    "        val_accu = np.mean(val_accu)\n",
    "        val_loss = np.mean(val_loss)\n",
    "        print(\"Val Loss: {:.4f} - Val Accuracy: {:.4f}\".format(val_loss, val_accu))\n",
    "        \n",
    "        trial.report(val_accu, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    global best_accu\n",
    "    if val_accu > best_accu:\n",
    "        best_accu = val_accu\n",
    "        print(\"Saving best model...\")\n",
    "        torch.save(model_xtr.state_dict(), \"../vit_8-8_arcface_mean.pt\")\n",
    "            \n",
    "    return val_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b96ee89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-07 20:51:59,530]\u001b[0m Using an existing study with name 'arcface-8-8-mean-vit-study' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate for Loss: 0.0009233611225501734\n",
      "Learning rate: 0.03828681316753371\n",
      "Weight decay: 0.0024370304518440133\n",
      "Epsilon: 3.433742523312084e-09\n",
      "Batch size: 56\n",
      "Number of epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   0%|          | 1/250 [00:00<02:06,  1.97it/s]\u001b[A\n",
      "Training:   2%|▏         | 5/250 [00:00<00:24,  9.92it/s]\u001b[A\n",
      "Training:   4%|▎         | 9/250 [00:00<00:15, 15.36it/s]\u001b[A\n",
      "Training:   5%|▍         | 12/250 [00:00<00:13, 17.13it/s]\u001b[A\n",
      "Training:   6%|▌         | 15/250 [00:01<00:12, 19.34it/s]\u001b[A\n",
      "Training:   7%|▋         | 18/250 [00:01<00:11, 20.74it/s]\u001b[A\n",
      "Training:   9%|▉         | 22/250 [00:01<00:09, 23.06it/s]\u001b[A\n",
      "Training:  10%|█         | 26/250 [00:01<00:08, 25.12it/s]\u001b[A\n",
      "Training:  12%|█▏        | 30/250 [00:01<00:08, 26.05it/s]\u001b[A\n",
      "Training:  14%|█▎        | 34/250 [00:01<00:07, 27.00it/s]\u001b[A\n",
      "Training:  15%|█▌        | 38/250 [00:01<00:07, 27.55it/s]\u001b[A\n",
      "Training:  17%|█▋        | 42/250 [00:01<00:07, 27.12it/s]\u001b[A\n",
      "Training:  18%|█▊        | 46/250 [00:02<00:07, 27.01it/s]\u001b[A\n",
      "Training:  20%|██        | 50/250 [00:02<00:07, 27.27it/s]\u001b[A\n",
      "Training:  22%|██▏       | 54/250 [00:02<00:07, 27.64it/s]\u001b[A\n",
      "Training:  23%|██▎       | 58/250 [00:02<00:06, 27.47it/s]\u001b[A\n",
      "Training:  25%|██▍       | 62/250 [00:02<00:06, 27.75it/s]\u001b[A\n",
      "Training:  26%|██▋       | 66/250 [00:02<00:06, 27.73it/s]\u001b[A\n",
      "Training:  28%|██▊       | 70/250 [00:03<00:06, 27.58it/s]\u001b[A\n",
      "Training:  30%|██▉       | 74/250 [00:03<00:06, 27.30it/s]\u001b[A\n",
      "Training:  31%|███       | 78/250 [00:03<00:06, 27.18it/s]\u001b[A\n",
      "Training:  33%|███▎      | 82/250 [00:03<00:06, 26.36it/s]\u001b[A\n",
      "Training:  34%|███▍      | 86/250 [00:03<00:06, 26.78it/s]\u001b[A\n",
      "Training:  36%|███▌      | 90/250 [00:03<00:06, 26.66it/s]\u001b[A\n",
      "Training:  38%|███▊      | 94/250 [00:03<00:05, 26.90it/s]\u001b[A\n",
      "Training:  39%|███▉      | 98/250 [00:04<00:05, 27.13it/s]\u001b[A\n",
      "Training:  41%|████      | 102/250 [00:04<00:05, 26.38it/s]\u001b[A\n",
      "Training:  42%|████▏     | 106/250 [00:04<00:05, 26.46it/s]\u001b[A\n",
      "Training:  44%|████▍     | 110/250 [00:04<00:05, 26.15it/s]\u001b[A\n",
      "Training:  46%|████▌     | 114/250 [00:04<00:05, 26.51it/s]\u001b[A\n",
      "Training:  47%|████▋     | 118/250 [00:04<00:04, 26.83it/s]\u001b[A\n",
      "Training:  49%|████▉     | 122/250 [00:04<00:04, 26.82it/s]\u001b[A\n",
      "Training:  50%|█████     | 126/250 [00:05<00:04, 26.66it/s]\u001b[A\n",
      "Training:  52%|█████▏    | 130/250 [00:05<00:04, 26.30it/s]\u001b[A\n",
      "Training:  54%|█████▎    | 134/250 [00:05<00:04, 26.61it/s]\u001b[A\n",
      "Training:  55%|█████▌    | 138/250 [00:05<00:04, 26.53it/s]\u001b[A\n",
      "Training:  57%|█████▋    | 142/250 [00:05<00:04, 26.57it/s]\u001b[A\n",
      "Training:  58%|█████▊    | 146/250 [00:05<00:03, 26.99it/s]\u001b[A\n",
      "Training:  60%|██████    | 150/250 [00:06<00:03, 27.04it/s]\u001b[A\n",
      "Training:  62%|██████▏   | 154/250 [00:06<00:03, 26.68it/s]\u001b[A\n",
      "Training:  63%|██████▎   | 158/250 [00:06<00:03, 26.68it/s]\u001b[A\n",
      "Training:  65%|██████▍   | 162/250 [00:06<00:03, 26.54it/s]\u001b[A\n",
      "Training:  66%|██████▋   | 166/250 [00:06<00:03, 26.45it/s]\u001b[A\n",
      "Training:  68%|██████▊   | 170/250 [00:06<00:03, 26.45it/s]\u001b[A\n",
      "Training:  70%|██████▉   | 174/250 [00:06<00:02, 26.42it/s]\u001b[A\n",
      "Training:  71%|███████   | 178/250 [00:07<00:02, 26.06it/s]\u001b[A\n",
      "Training:  73%|███████▎  | 182/250 [00:07<00:02, 26.06it/s]\u001b[A\n",
      "Training:  74%|███████▍  | 186/250 [00:07<00:02, 26.09it/s]\u001b[A\n",
      "Training:  76%|███████▌  | 190/250 [00:07<00:02, 26.32it/s]\u001b[A\n",
      "Training:  78%|███████▊  | 194/250 [00:07<00:02, 26.42it/s]\u001b[A\n",
      "Training:  79%|███████▉  | 198/250 [00:07<00:02, 25.71it/s]\u001b[A\n",
      "Training:  81%|████████  | 202/250 [00:08<00:01, 25.77it/s]\u001b[A\n",
      "Training:  82%|████████▏ | 206/250 [00:08<00:01, 25.88it/s]\u001b[A\n",
      "Training:  84%|████████▍ | 210/250 [00:08<00:01, 26.00it/s]\u001b[A\n",
      "Training:  86%|████████▌ | 214/250 [00:08<00:01, 25.95it/s]\u001b[A\n",
      "Training:  87%|████████▋ | 218/250 [00:08<00:01, 25.89it/s]\u001b[A\n",
      "Training:  89%|████████▉ | 222/250 [00:08<00:01, 26.22it/s]\u001b[A\n",
      "Training:  90%|█████████ | 226/250 [00:08<00:00, 25.99it/s]\u001b[A\n",
      "Training:  92%|█████████▏| 230/250 [00:09<00:00, 25.84it/s]\u001b[A\n",
      "Training:  94%|█████████▎| 234/250 [00:09<00:00, 25.84it/s]\u001b[A\n",
      "Training:  95%|█████████▌| 238/250 [00:09<00:00, 26.16it/s]\u001b[A\n",
      "Training:  97%|█████████▋| 242/250 [00:09<00:00, 26.01it/s]\u001b[A\n",
      "Training:  98%|█████████▊| 246/250 [00:09<00:00, 26.35it/s]\u001b[A\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 - Loss: 24.7942 - Accuracy: 0.8443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/32 [00:00<00:11,  2.64it/s]\u001b[A\n",
      " 16%|█▌        | 5/32 [00:00<00:02, 10.87it/s]\u001b[A\n",
      " 28%|██▊       | 9/32 [00:00<00:01, 16.24it/s]\u001b[A\n",
      " 41%|████      | 13/32 [00:00<00:00, 19.75it/s]\u001b[A\n",
      " 53%|█████▎    | 17/32 [00:00<00:00, 22.11it/s]\u001b[A\n",
      " 66%|██████▌   | 21/32 [00:01<00:00, 23.38it/s]\u001b[A\n",
      " 78%|███████▊  | 25/32 [00:01<00:00, 24.25it/s]\u001b[A\n",
      "100%|██████████| 32/32 [00:01<00:00, 21.20it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/100 [00:11<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:52:11,376]\u001b[0m Trial 10 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 21.7157 - Val Accuracy: 0.8927\n",
      "Learning rate for Loss: 0.00820579089904839\n",
      "Learning rate: 0.00015364919241506037\n",
      "Weight decay: 0.0002767023750603174\n",
      "Epsilon: 1.810503395532833e-09\n",
      "Batch size: 234\n",
      "Number of epochs: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/34 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/60 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   2%|▏         | 1/60 [00:00<00:50,  1.16it/s]\u001b[A\n",
      "Training:   8%|▊         | 5/60 [00:01<00:14,  3.93it/s]\u001b[A\n",
      "Training:  15%|█▌        | 9/60 [00:02<00:09,  5.19it/s]\u001b[A\n",
      "Training:  22%|██▏       | 13/60 [00:02<00:08,  5.81it/s]\u001b[A\n",
      "Training:  28%|██▊       | 17/60 [00:03<00:07,  6.11it/s]\u001b[A\n",
      "Training:  35%|███▌      | 21/60 [00:03<00:06,  6.45it/s]\u001b[A\n",
      "Training:  42%|████▏     | 25/60 [00:04<00:05,  6.62it/s]\u001b[A\n",
      "Training:  48%|████▊     | 29/60 [00:04<00:04,  6.81it/s]\u001b[A\n",
      "Training:  55%|█████▌    | 33/60 [00:05<00:03,  6.84it/s]\u001b[A\n",
      "Training:  62%|██████▏   | 37/60 [00:06<00:03,  6.95it/s]\u001b[A\n",
      "Training:  68%|██████▊   | 41/60 [00:06<00:02,  7.01it/s]\u001b[A\n",
      "Training:  75%|███████▌  | 45/60 [00:07<00:02,  7.05it/s]\u001b[A\n",
      "Training:  82%|████████▏ | 49/60 [00:07<00:01,  7.08it/s]\u001b[A\n",
      "Training:  88%|████████▊ | 53/60 [00:08<00:00,  7.10it/s]\u001b[A\n",
      "Training:  95%|█████████▌| 57/60 [00:08<00:00,  7.10it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/34 - Loss: 14.3772 - Accuracy: 0.7995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:06,  1.12it/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:01<00:00,  5.05it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:01<00:00,  4.92it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/34 [00:10<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:52:22,263]\u001b[0m Trial 11 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 6.6593 - Val Accuracy: 0.9095\n",
      "Learning rate for Loss: 0.002010369672178752\n",
      "Learning rate: 0.008272134907077715\n",
      "Weight decay: 0.0018539875985396422\n",
      "Epsilon: 1.0393375964254468e-09\n",
      "Batch size: 226\n",
      "Number of epochs: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/42 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   2%|▏         | 1/62 [00:00<00:50,  1.20it/s]\u001b[A\n",
      "Training:   8%|▊         | 5/62 [00:01<00:13,  4.15it/s]\u001b[A\n",
      "Training:  15%|█▍        | 9/62 [00:01<00:09,  5.36it/s]\u001b[A\n",
      "Training:  21%|██        | 13/62 [00:02<00:08,  6.00it/s]\u001b[A\n",
      "Training:  27%|██▋       | 17/62 [00:03<00:06,  6.47it/s]\u001b[A\n",
      "Training:  34%|███▍      | 21/62 [00:03<00:06,  6.76it/s]\u001b[A\n",
      "Training:  40%|████      | 25/62 [00:04<00:05,  6.93it/s]\u001b[A\n",
      "Training:  47%|████▋     | 29/62 [00:04<00:04,  7.09it/s]\u001b[A\n",
      "Training:  53%|█████▎    | 33/62 [00:05<00:04,  7.15it/s]\u001b[A\n",
      "Training:  60%|█████▉    | 37/62 [00:05<00:03,  7.25it/s]\u001b[A\n",
      "Training:  66%|██████▌   | 41/62 [00:06<00:02,  7.19it/s]\u001b[A\n",
      "Training:  73%|███████▎  | 45/62 [00:06<00:02,  7.18it/s]\u001b[A\n",
      "Training:  79%|███████▉  | 49/62 [00:07<00:01,  7.23it/s]\u001b[A\n",
      "Training:  85%|████████▌ | 53/62 [00:07<00:01,  7.31it/s]\u001b[A\n",
      "Training:  92%|█████████▏| 57/62 [00:08<00:00,  7.25it/s]\u001b[A\n",
      "Training:  98%|█████████▊| 61/62 [00:09<00:00,  7.18it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/42 - Loss: 7.6307 - Accuracy: 0.8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:06,  1.14it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.01it/s]\u001b[A\n",
      "Epochs:   2%|▏         | 1/42 [00:10<07:24, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 3.2179 - Val Accuracy: 0.9212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/62 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   2%|▏         | 1/62 [00:00<00:50,  1.21it/s]\u001b[A\n",
      "Training:   8%|▊         | 5/62 [00:01<00:13,  4.20it/s]\u001b[A\n",
      "Training:  15%|█▍        | 9/62 [00:01<00:09,  5.40it/s]\u001b[A\n",
      "Training:  21%|██        | 13/62 [00:02<00:08,  6.07it/s]\u001b[A\n",
      "Training:  27%|██▋       | 17/62 [00:03<00:06,  6.50it/s]\u001b[A\n",
      "Training:  34%|███▍      | 21/62 [00:03<00:06,  6.78it/s]\u001b[A\n",
      "Training:  40%|████      | 25/62 [00:04<00:05,  6.97it/s]\u001b[A\n",
      "Training:  47%|████▋     | 29/62 [00:04<00:04,  7.08it/s]\u001b[A\n",
      "Training:  53%|█████▎    | 33/62 [00:05<00:04,  7.17it/s]\u001b[A\n",
      "Training:  60%|█████▉    | 37/62 [00:05<00:03,  7.18it/s]\u001b[A\n",
      "Training:  66%|██████▌   | 41/62 [00:06<00:02,  7.14it/s]\u001b[A\n",
      "Training:  73%|███████▎  | 45/62 [00:06<00:02,  7.16it/s]\u001b[A\n",
      "Training:  79%|███████▉  | 49/62 [00:07<00:01,  7.27it/s]\u001b[A\n",
      "Training:  85%|████████▌ | 53/62 [00:07<00:01,  7.31it/s]\u001b[A\n",
      "Training:  92%|█████████▏| 57/62 [00:08<00:00,  7.32it/s]\u001b[A\n",
      "Training:  98%|█████████▊| 61/62 [00:09<00:00,  7.20it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/42 - Loss: 2.6093 - Accuracy: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:06,  1.14it/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:01<00:00,  5.03it/s]\u001b[A\n",
      "Epochs:   2%|▏         | 1/42 [00:21<14:47, 21.65s/it]\n",
      "\u001b[32m[I 2023-12-07 20:52:44,162]\u001b[0m Trial 12 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 2.5575 - Val Accuracy: 0.9086\n",
      "Learning rate for Loss: 0.0005254730934824125\n",
      "Learning rate: 0.0001343483811328187\n",
      "Weight decay: 0.0002718073491237901\n",
      "Epsilon: 4.49837148852805e-09\n",
      "Batch size: 62\n",
      "Number of epochs: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/81 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/226 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   0%|          | 1/226 [00:00<01:29,  2.52it/s]\u001b[A\n",
      "Training:   2%|▏         | 5/226 [00:00<00:20, 11.01it/s]\u001b[A\n",
      "Training:   4%|▍         | 9/226 [00:00<00:13, 16.32it/s]\u001b[A\n",
      "Training:   6%|▌         | 13/226 [00:00<00:10, 19.61it/s]\u001b[A\n",
      "Training:   8%|▊         | 17/226 [00:00<00:09, 21.72it/s]\u001b[A\n",
      "Training:   9%|▉         | 21/226 [00:01<00:08, 22.92it/s]\u001b[A\n",
      "Training:  11%|█         | 25/226 [00:01<00:08, 24.00it/s]\u001b[A\n",
      "Training:  13%|█▎        | 29/226 [00:01<00:07, 24.94it/s]\u001b[A\n",
      "Training:  15%|█▍        | 33/226 [00:01<00:07, 25.52it/s]\u001b[A\n",
      "Training:  16%|█▋        | 37/226 [00:01<00:07, 25.52it/s]\u001b[A\n",
      "Training:  18%|█▊        | 41/226 [00:01<00:07, 25.75it/s]\u001b[A\n",
      "Training:  20%|█▉        | 45/226 [00:02<00:06, 26.40it/s]\u001b[A\n",
      "Training:  22%|██▏       | 49/226 [00:02<00:06, 26.33it/s]\u001b[A\n",
      "Training:  23%|██▎       | 53/226 [00:02<00:06, 25.41it/s]\u001b[A\n",
      "Training:  25%|██▌       | 57/226 [00:02<00:06, 26.03it/s]\u001b[A\n",
      "Training:  27%|██▋       | 61/226 [00:02<00:06, 26.04it/s]\u001b[A\n",
      "Training:  29%|██▉       | 65/226 [00:02<00:06, 26.18it/s]\u001b[A\n",
      "Training:  31%|███       | 69/226 [00:02<00:05, 26.32it/s]\u001b[A\n",
      "Training:  32%|███▏      | 73/226 [00:03<00:05, 26.60it/s]\u001b[A\n",
      "Training:  34%|███▍      | 77/226 [00:03<00:05, 26.85it/s]\u001b[A\n",
      "Training:  36%|███▌      | 81/226 [00:03<00:05, 27.01it/s]\u001b[A\n",
      "Training:  38%|███▊      | 85/226 [00:03<00:05, 26.57it/s]\u001b[A\n",
      "Training:  39%|███▉      | 89/226 [00:03<00:05, 26.50it/s]\u001b[A\n",
      "Training:  41%|████      | 93/226 [00:03<00:05, 26.13it/s]\u001b[A\n",
      "Training:  43%|████▎     | 97/226 [00:04<00:04, 26.02it/s]\u001b[A\n",
      "Training:  45%|████▍     | 101/226 [00:04<00:04, 26.44it/s]\u001b[A\n",
      "Training:  46%|████▋     | 105/226 [00:04<00:04, 26.67it/s]\u001b[A\n",
      "Training:  48%|████▊     | 109/226 [00:04<00:04, 26.24it/s]\u001b[A\n",
      "Training:  50%|█████     | 113/226 [00:04<00:04, 26.56it/s]\u001b[A\n",
      "Training:  52%|█████▏    | 117/226 [00:04<00:04, 26.58it/s]\u001b[A\n",
      "Training:  54%|█████▎    | 121/226 [00:04<00:03, 26.76it/s]\u001b[A\n",
      "Training:  55%|█████▌    | 125/226 [00:05<00:03, 26.44it/s]\u001b[A\n",
      "Training:  57%|█████▋    | 129/226 [00:05<00:03, 26.51it/s]\u001b[A\n",
      "Training:  59%|█████▉    | 133/226 [00:05<00:03, 26.57it/s]\u001b[A\n",
      "Training:  61%|██████    | 137/226 [00:05<00:03, 26.38it/s]\u001b[A\n",
      "Training:  62%|██████▏   | 141/226 [00:05<00:03, 26.17it/s]\u001b[A\n",
      "Training:  64%|██████▍   | 145/226 [00:05<00:03, 26.09it/s]\u001b[A\n",
      "Training:  65%|██████▌   | 148/226 [00:05<00:02, 26.60it/s]\u001b[A\n",
      "Training:  67%|██████▋   | 151/226 [00:06<00:03, 24.44it/s]\u001b[A\n",
      "Training:  69%|██████▊   | 155/226 [00:06<00:02, 24.94it/s]\u001b[A\n",
      "Training:  70%|███████   | 159/226 [00:06<00:02, 25.20it/s]\u001b[A\n",
      "Training:  72%|███████▏  | 163/226 [00:06<00:02, 25.04it/s]\u001b[A\n",
      "Training:  74%|███████▍  | 167/226 [00:06<00:02, 25.38it/s]\u001b[A\n",
      "Training:  76%|███████▌  | 171/226 [00:06<00:02, 25.07it/s]\u001b[A\n",
      "Training:  77%|███████▋  | 175/226 [00:07<00:02, 25.18it/s]\u001b[A\n",
      "Training:  79%|███████▉  | 179/226 [00:07<00:01, 25.63it/s]\u001b[A\n",
      "Training:  81%|████████  | 183/226 [00:07<00:01, 25.60it/s]\u001b[A\n",
      "Training:  83%|████████▎ | 187/226 [00:07<00:01, 25.68it/s]\u001b[A\n",
      "Training:  85%|████████▍ | 191/226 [00:07<00:01, 25.63it/s]\u001b[A\n",
      "Training:  86%|████████▋ | 195/226 [00:07<00:01, 25.84it/s]\u001b[A\n",
      "Training:  88%|████████▊ | 199/226 [00:07<00:01, 25.71it/s]\u001b[A\n",
      "Training:  90%|████████▉ | 203/226 [00:08<00:00, 25.81it/s]\u001b[A\n",
      "Training:  92%|█████████▏| 207/226 [00:08<00:00, 25.06it/s]\u001b[A\n",
      "Training:  93%|█████████▎| 211/226 [00:08<00:00, 25.30it/s]\u001b[A\n",
      "Training:  95%|█████████▌| 215/226 [00:08<00:00, 25.24it/s]\u001b[A\n",
      "Training:  97%|█████████▋| 219/226 [00:08<00:00, 25.35it/s]\u001b[A\n",
      "Training:  99%|█████████▊| 223/226 [00:08<00:00, 25.32it/s]\u001b[A\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/81 - Loss: 9.8352 - Accuracy: 0.8604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/29 [00:00<00:11,  2.46it/s]\u001b[A\n",
      " 17%|█▋        | 5/29 [00:00<00:02, 10.32it/s]\u001b[A\n",
      " 31%|███       | 9/29 [00:00<00:01, 14.91it/s]\u001b[A\n",
      " 45%|████▍     | 13/29 [00:00<00:00, 17.68it/s]\u001b[A\n",
      " 59%|█████▊    | 17/29 [00:01<00:00, 19.62it/s]\u001b[A\n",
      " 72%|███████▏  | 21/29 [00:01<00:00, 20.78it/s]\u001b[A\n",
      "100%|██████████| 29/29 [00:01<00:00, 18.98it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/81 [00:10<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:52:54,995]\u001b[0m Trial 13 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.8549 - Val Accuracy: 0.9050\n",
      "Learning rate for Loss: 0.004725291999976461\n",
      "Learning rate: 0.005358794491244823\n",
      "Weight decay: 0.0003556283031120871\n",
      "Epsilon: 5.672565099667101e-09\n",
      "Batch size: 207\n",
      "Number of epochs: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/45 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/68 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   1%|▏         | 1/68 [00:00<00:50,  1.32it/s]\u001b[A\n",
      "Training:   7%|▋         | 5/68 [00:01<00:13,  4.56it/s]\u001b[A\n",
      "Training:  13%|█▎        | 9/68 [00:01<00:09,  5.99it/s]\u001b[A\n",
      "Training:  19%|█▉        | 13/68 [00:02<00:08,  6.68it/s]\u001b[A\n",
      "Training:  25%|██▌       | 17/68 [00:02<00:07,  7.13it/s]\u001b[A\n",
      "Training:  31%|███       | 21/68 [00:03<00:06,  7.36it/s]\u001b[A\n",
      "Training:  37%|███▋      | 25/68 [00:03<00:05,  7.53it/s]\u001b[A\n",
      "Training:  43%|████▎     | 29/68 [00:04<00:05,  7.60it/s]\u001b[A\n",
      "Training:  49%|████▊     | 33/68 [00:04<00:04,  7.71it/s]\u001b[A\n",
      "Training:  54%|█████▍    | 37/68 [00:05<00:04,  7.71it/s]\u001b[A\n",
      "Training:  60%|██████    | 41/68 [00:05<00:03,  7.77it/s]\u001b[A\n",
      "Training:  66%|██████▌   | 45/68 [00:06<00:02,  7.81it/s]\u001b[A\n",
      "Training:  71%|███████   | 48/68 [00:06<00:02,  9.53it/s]\u001b[A\n",
      "Training:  74%|███████▎  | 50/68 [00:06<00:02,  7.88it/s]\u001b[A\n",
      "Training:  78%|███████▊  | 53/68 [00:07<00:02,  7.38it/s]\u001b[A\n",
      "Training:  82%|████████▏ | 56/68 [00:07<00:01,  9.30it/s]\u001b[A\n",
      "Training:  85%|████████▌ | 58/68 [00:07<00:01,  7.61it/s]\u001b[A\n",
      "Training:  90%|████████▉ | 61/68 [00:08<00:00,  7.16it/s]\u001b[A\n",
      "Training:  93%|█████████▎| 63/68 [00:08<00:00,  8.27it/s]\u001b[A\n",
      "Training:  96%|█████████▌| 65/68 [00:08<00:00,  7.12it/s]\u001b[A\n",
      "Training:  99%|█████████▊| 67/68 [00:08<00:00,  8.55it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/45 - Loss: 5.1322 - Accuracy: 0.8617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 1/9 [00:00<00:06,  1.20it/s]\u001b[A\n",
      " 56%|█████▌    | 5/9 [00:01<00:00,  4.14it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.37it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/45 [00:10<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:53:06,051]\u001b[0m Trial 14 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 2.6232 - Val Accuracy: 0.9161\n",
      "Learning rate for Loss: 0.0018172682948593003\n",
      "Learning rate: 0.05545058398688582\n",
      "Weight decay: 0.001401980381031568\n",
      "Epsilon: 8.834252536741359e-08\n",
      "Batch size: 257\n",
      "Number of epochs: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/41 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   2%|▏         | 1/55 [00:00<00:50,  1.08it/s]\u001b[A\n",
      "Training:   9%|▉         | 5/55 [00:01<00:13,  3.68it/s]\u001b[A\n",
      "Training:  16%|█▋        | 9/55 [00:02<00:09,  4.75it/s]\u001b[A\n",
      "Training:  24%|██▎       | 13/55 [00:02<00:07,  5.38it/s]\u001b[A\n",
      "Training:  31%|███       | 17/55 [00:03<00:06,  5.68it/s]\u001b[A\n",
      "Training:  38%|███▊      | 21/55 [00:04<00:05,  5.90it/s]\u001b[A\n",
      "Training:  45%|████▌     | 25/55 [00:04<00:04,  6.03it/s]\u001b[A\n",
      "Training:  53%|█████▎    | 29/55 [00:05<00:04,  6.16it/s]\u001b[A\n",
      "Training:  60%|██████    | 33/55 [00:05<00:03,  6.25it/s]\u001b[A\n",
      "Training:  67%|██████▋   | 37/55 [00:06<00:02,  6.30it/s]\u001b[A\n",
      "Training:  75%|███████▍  | 41/55 [00:07<00:02,  6.29it/s]\u001b[A\n",
      "Training:  82%|████████▏ | 45/55 [00:07<00:01,  6.35it/s]\u001b[A\n",
      "Training:  89%|████████▉ | 49/55 [00:08<00:00,  6.33it/s]\u001b[A\n",
      "Training:  96%|█████████▋| 53/55 [00:09<00:00,  6.31it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/41 - Loss: 124.0211 - Accuracy: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.01it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  3.89it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/41 [00:11<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:53:17,354]\u001b[0m Trial 15 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 10.7497 - Val Accuracy: 0.9063\n",
      "Learning rate for Loss: 0.0005216276745841489\n",
      "Learning rate: 5.50166763437879e-05\n",
      "Weight decay: 0.00017626042980704932\n",
      "Epsilon: 2.3430079328995787e-08\n",
      "Batch size: 93\n",
      "Number of epochs: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/19 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/151 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   1%|          | 1/151 [00:00<01:06,  2.26it/s]\u001b[A\n",
      "Training:   3%|▎         | 5/151 [00:00<00:16,  8.77it/s]\u001b[A\n",
      "Training:   6%|▌         | 9/151 [00:00<00:11, 12.13it/s]\u001b[A\n",
      "Training:   9%|▊         | 13/151 [00:01<00:09, 14.11it/s]\u001b[A\n",
      "Training:  11%|█▏        | 17/151 [00:01<00:08, 15.28it/s]\u001b[A\n",
      "Training:  14%|█▍        | 21/151 [00:01<00:08, 15.74it/s]\u001b[A\n",
      "Training:  17%|█▋        | 25/151 [00:01<00:07, 16.28it/s]\u001b[A\n",
      "Training:  19%|█▉        | 29/151 [00:02<00:07, 16.82it/s]\u001b[A\n",
      "Training:  22%|██▏       | 33/151 [00:02<00:06, 17.25it/s]\u001b[A\n",
      "Training:  25%|██▍       | 37/151 [00:02<00:06, 17.40it/s]\u001b[A\n",
      "Training:  27%|██▋       | 41/151 [00:02<00:06, 17.26it/s]\u001b[A\n",
      "Training:  30%|██▉       | 45/151 [00:02<00:06, 17.44it/s]\u001b[A\n",
      "Training:  32%|███▏      | 49/151 [00:03<00:05, 17.41it/s]\u001b[A\n",
      "Training:  35%|███▌      | 53/151 [00:03<00:05, 17.45it/s]\u001b[A\n",
      "Training:  38%|███▊      | 57/151 [00:03<00:05, 17.43it/s]\u001b[A\n",
      "Training:  40%|████      | 61/151 [00:03<00:05, 17.29it/s]\u001b[A\n",
      "Training:  43%|████▎     | 65/151 [00:04<00:04, 17.65it/s]\u001b[A\n",
      "Training:  46%|████▌     | 69/151 [00:04<00:04, 17.68it/s]\u001b[A\n",
      "Training:  48%|████▊     | 73/151 [00:04<00:04, 17.60it/s]\u001b[A\n",
      "Training:  51%|█████     | 77/151 [00:04<00:04, 17.65it/s]\u001b[A\n",
      "Training:  54%|█████▎    | 81/151 [00:04<00:03, 17.52it/s]\u001b[A\n",
      "Training:  56%|█████▋    | 85/151 [00:05<00:03, 17.68it/s]\u001b[A\n",
      "Training:  59%|█████▉    | 89/151 [00:05<00:03, 17.88it/s]\u001b[A\n",
      "Training:  62%|██████▏   | 93/151 [00:05<00:03, 17.71it/s]\u001b[A\n",
      "Training:  64%|██████▍   | 97/151 [00:05<00:03, 17.66it/s]\u001b[A\n",
      "Training:  67%|██████▋   | 101/151 [00:06<00:02, 17.21it/s]\u001b[A\n",
      "Training:  70%|██████▉   | 105/151 [00:06<00:02, 17.41it/s]\u001b[A\n",
      "Training:  72%|███████▏  | 109/151 [00:06<00:02, 17.55it/s]\u001b[A\n",
      "Training:  75%|███████▍  | 113/151 [00:06<00:02, 17.84it/s]\u001b[A\n",
      "Training:  77%|███████▋  | 117/151 [00:07<00:01, 17.75it/s]\u001b[A\n",
      "Training:  80%|████████  | 121/151 [00:07<00:01, 17.54it/s]\u001b[A\n",
      "Training:  83%|████████▎ | 125/151 [00:07<00:01, 17.65it/s]\u001b[A\n",
      "Training:  85%|████████▌ | 129/151 [00:07<00:01, 17.64it/s]\u001b[A\n",
      "Training:  88%|████████▊ | 133/151 [00:07<00:01, 17.62it/s]\u001b[A\n",
      "Training:  91%|█████████ | 137/151 [00:08<00:00, 17.33it/s]\u001b[A\n",
      "Training:  93%|█████████▎| 141/151 [00:08<00:00, 17.34it/s]\u001b[A\n",
      "Training:  96%|█████████▌| 145/151 [00:08<00:00, 17.42it/s]\u001b[A\n",
      "Training:  99%|█████████▊| 149/151 [00:08<00:00, 17.59it/s]\u001b[A\n",
      "                                                           \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/19 - Loss: 17.7219 - Accuracy: 0.7609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/19 [00:00<00:08,  2.03it/s]\u001b[A\n",
      " 26%|██▋       | 5/19 [00:00<00:01,  7.87it/s]\u001b[A\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 10.99it/s]\u001b[A\n",
      " 68%|██████▊   | 13/19 [00:01<00:00, 12.41it/s]\u001b[A\n",
      "100%|██████████| 19/19 [00:01<00:00, 12.07it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/19 [00:10<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:53:28,154]\u001b[0m Trial 16 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 10.1930 - Val Accuracy: 0.9003\n",
      "Learning rate for Loss: 0.0002705105262705772\n",
      "Learning rate: 0.0034362578330984555\n",
      "Weight decay: 0.00037861412975971495\n",
      "Epsilon: 2.400120132265128e-09\n",
      "Batch size: 191\n",
      "Number of epochs: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/73 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/74 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   1%|▏         | 1/74 [00:00<00:53,  1.37it/s]\u001b[A\n",
      "Training:   7%|▋         | 5/74 [00:01<00:14,  4.85it/s]\u001b[A\n",
      "Training:  12%|█▏        | 9/74 [00:01<00:10,  6.31it/s]\u001b[A\n",
      "Training:  18%|█▊        | 13/74 [00:02<00:08,  7.12it/s]\u001b[A\n",
      "Training:  23%|██▎       | 17/74 [00:02<00:07,  7.65it/s]\u001b[A\n",
      "Training:  28%|██▊       | 21/74 [00:03<00:06,  7.96it/s]\u001b[A\n",
      "Training:  34%|███▍      | 25/74 [00:03<00:05,  8.20it/s]\u001b[A\n",
      "Training:  39%|███▉      | 29/74 [00:03<00:05,  8.32it/s]\u001b[A\n",
      "Training:  45%|████▍     | 33/74 [00:04<00:04,  8.46it/s]\u001b[A\n",
      "Training:  50%|█████     | 37/74 [00:04<00:04,  8.41it/s]\u001b[A\n",
      "Training:  55%|█████▌    | 41/74 [00:05<00:03,  8.47it/s]\u001b[A\n",
      "Training:  61%|██████    | 45/74 [00:05<00:03,  8.48it/s]\u001b[A\n",
      "Training:  66%|██████▌   | 49/74 [00:06<00:02,  8.61it/s]\u001b[A\n",
      "Training:  72%|███████▏  | 53/74 [00:06<00:02,  8.49it/s]\u001b[A\n",
      "Training:  77%|███████▋  | 57/74 [00:07<00:01,  8.55it/s]\u001b[A\n",
      "Training:  82%|████████▏ | 61/74 [00:07<00:01,  8.60it/s]\u001b[A\n",
      "Training:  88%|████████▊ | 65/74 [00:08<00:01,  8.48it/s]\u001b[A\n",
      "Training:  93%|█████████▎| 69/74 [00:08<00:00,  8.40it/s]\u001b[A\n",
      "Training:  99%|█████████▊| 73/74 [00:09<00:00,  8.37it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/73 - Loss: 6.0735 - Accuracy: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:00<00:06,  1.34it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [00:01<00:01,  4.48it/s]\u001b[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.34it/s][A\n",
      "Epochs:   0%|          | 0/73 [00:11<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:53:39,560]\u001b[0m Trial 17 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 3.5009 - Val Accuracy: 0.9158\n",
      "Learning rate for Loss: 0.0008856753006887652\n",
      "Learning rate: 0.017677771848393038\n",
      "Weight decay: 0.0036388531317124856\n",
      "Epsilon: 6.620230122167153e-09\n",
      "Batch size: 151\n",
      "Number of epochs: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/45 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/93 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   1%|          | 1/93 [00:00<00:56,  1.63it/s]\u001b[A\n",
      "Training:   5%|▌         | 5/93 [00:00<00:14,  5.92it/s]\u001b[A\n",
      "Training:  10%|▉         | 9/93 [00:01<00:10,  7.88it/s]\u001b[A\n",
      "Training:  14%|█▍        | 13/93 [00:01<00:08,  8.95it/s]\u001b[A\n",
      "Training:  18%|█▊        | 17/93 [00:02<00:07,  9.65it/s]\u001b[A\n",
      "Training:  23%|██▎       | 21/93 [00:02<00:07, 10.10it/s]\u001b[A\n",
      "Training:  27%|██▋       | 25/93 [00:02<00:06, 10.40it/s]\u001b[A\n",
      "Training:  31%|███       | 29/93 [00:03<00:06, 10.59it/s]\u001b[A\n",
      "Training:  35%|███▌      | 33/93 [00:03<00:05, 10.71it/s]\u001b[A\n",
      "Training:  40%|███▉      | 37/93 [00:03<00:05, 10.73it/s]\u001b[A\n",
      "Training:  44%|████▍     | 41/93 [00:04<00:04, 10.79it/s]\u001b[A\n",
      "Training:  48%|████▊     | 45/93 [00:04<00:04, 10.73it/s]\u001b[A\n",
      "Training:  53%|█████▎    | 49/93 [00:05<00:04, 10.79it/s]\u001b[A\n",
      "Training:  57%|█████▋    | 53/93 [00:05<00:03, 10.82it/s]\u001b[A\n",
      "Training:  61%|██████▏   | 57/93 [00:05<00:03, 10.74it/s]\u001b[A\n",
      "Training:  66%|██████▌   | 61/93 [00:06<00:02, 10.87it/s]\u001b[A\n",
      "Training:  70%|██████▉   | 65/93 [00:06<00:02, 10.86it/s]\u001b[A\n",
      "Training:  74%|███████▍  | 69/93 [00:06<00:02, 10.91it/s]\u001b[A\n",
      "Training:  78%|███████▊  | 73/93 [00:07<00:01, 10.81it/s]\u001b[A\n",
      "Training:  83%|████████▎ | 77/93 [00:07<00:01, 10.91it/s]\u001b[A\n",
      "Training:  87%|████████▋ | 81/93 [00:07<00:01, 10.93it/s]\u001b[A\n",
      "Training:  91%|█████████▏| 85/93 [00:08<00:00, 10.92it/s]\u001b[A\n",
      "Training:  96%|█████████▌| 89/93 [00:08<00:00, 11.00it/s]\u001b[A\n",
      "Training: 100%|██████████| 93/93 [00:08<00:00, 12.79it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/45 - Loss: 11.5889 - Accuracy: 0.8312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "  8%|▊         | 1/12 [00:00<00:07,  1.56it/s]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:01<00:01,  5.55it/s]\u001b[A\n",
      "100%|██████████| 12/12 [00:01<00:00,  7.78it/s][A\n",
      "Epochs:   0%|          | 0/45 [00:10<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:53:50,318]\u001b[0m Trial 18 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 3.8049 - Val Accuracy: 0.9197\n",
      "Learning rate for Loss: 0.0019908238676840553\n",
      "Learning rate: 0.0005623733773938865\n",
      "Weight decay: 0.0011554051156482828\n",
      "Epsilon: 1.8467391861919478e-09\n",
      "Batch size: 262\n",
      "Number of epochs: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/90 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/54 [00:00<?, ?it/s]\u001b[A\n",
      "Training:   2%|▏         | 1/54 [00:00<00:50,  1.06it/s]\u001b[A\n",
      "Training:   9%|▉         | 5/54 [00:01<00:13,  3.66it/s]\u001b[A\n",
      "Training:  17%|█▋        | 9/54 [00:02<00:09,  4.75it/s]\u001b[A\n",
      "Training:  24%|██▍       | 13/54 [00:02<00:07,  5.31it/s]\u001b[A\n",
      "Training:  31%|███▏      | 17/54 [00:03<00:06,  5.66it/s]\u001b[A\n",
      "Training:  39%|███▉      | 21/54 [00:04<00:05,  5.83it/s]\u001b[A\n",
      "Training:  46%|████▋     | 25/54 [00:04<00:04,  5.96it/s]\u001b[A\n",
      "Training:  54%|█████▎    | 29/54 [00:05<00:04,  6.09it/s]\u001b[A\n",
      "Training:  61%|██████    | 33/54 [00:06<00:03,  6.13it/s]\u001b[A\n",
      "Training:  69%|██████▊   | 37/54 [00:06<00:02,  6.15it/s]\u001b[A\n",
      "Training:  76%|███████▌  | 41/54 [00:07<00:02,  6.20it/s]\u001b[A\n",
      "Training:  83%|████████▎ | 45/54 [00:07<00:01,  6.22it/s]\u001b[A\n",
      "Training:  91%|█████████ | 49/54 [00:08<00:00,  6.26it/s]\u001b[A\n",
      "Training:  98%|█████████▊| 53/54 [00:09<00:00,  6.25it/s]\u001b[A\n",
      "                                                         \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/90 - Loss: 9.1214 - Accuracy: 0.8553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:00<00:05,  1.01it/s]\u001b[A\n",
      "100%|██████████| 7/7 [00:01<00:00,  3.90it/s]\u001b[A\n",
      "Epochs:   0%|          | 0/90 [00:11<?, ?it/s]\n",
      "\u001b[32m[I 2023-12-07 20:54:01,727]\u001b[0m Trial 19 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 3.9975 - Val Accuracy: 0.9189\n",
      "\n",
      "Study statistics: \n",
      "  Number of finished trials:  20\n",
      "  Number of pruned trials:  13\n",
      "  Number of complete trials:  7\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            study_name='arcface-8-8-mean-vit-study',\n",
    "                            storage='sqlite:///study1.db',\n",
    "                            load_if_exists=True)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "# Display the study statistics\n",
    "print(\"\\nStudy statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "567bacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  0.9446246027946472\n",
      "  Params: \n",
      "    batch_size: 127\n",
      "    epochs: 35\n",
      "    epsilon: 3.601242341054396e-08\n",
      "    learning_rate: 0.001556997542805148\n",
      "    loss_learning_rate: 0.0011138215118992293\n",
      "    weight_decay: 0.00021625482614416372\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e734bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT P8-S8 ArcFace Mean\n",
    "\n",
    "Best trial:\n",
    "Value:  0.9446246027946472\n",
    "Params: \n",
    "batch_size: 127\n",
    "epochs: 35\n",
    "epsilon: 3.601242341054396e-08\n",
    "learning_rate: 0.001556997542805148\n",
    "loss_learning_rate: 0.0011138215118992293\n",
    "weight_decay: 0.00021625482614416372"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
